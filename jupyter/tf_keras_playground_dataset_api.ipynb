{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_keras_playground_dataset_api.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"}},"cells":[{"metadata":{"id":"l0wMmfmYjMep","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","tf.enable_eager_execution()\n","# sess = tf.InteractiveSession()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tKOfGox1l6FA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"19964437-e77e-4a3d-c954-ec2b7f8b0e40","executionInfo":{"status":"ok","timestamp":1550225179646,"user_tz":-60,"elapsed":470,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}}},"cell_type":"code","source":["data = np.random.normal(0, 1, (10000, 4))\n","\n","def online_statistics(data):\n","    n = 0\n","    mean = 0\n","    M2 = 0\n","\n","    for x in data:\n","        n = n + 1\n","        delta = x - mean\n","        mean = mean + delta/n\n","        M2 = M2 + delta*(x - mean)\n","\n","    variance = M2/(n - 1)\n","    return mean, variance\n","\n","online_mean, online_var = online_statistics(data)\n","print(\"Online mean: {0}, online std: {1}\".format(online_mean, online_var))\n","\n","offline_mean = data.mean(axis=0)\n","offline_var = data.var(axis=0)\n","print(\"Offline mean: {0}, offline std: {1}\".format(offline_mean, offline_var))\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Online mean: [-0.00243011 -0.00168271  0.00190514 -0.01624116], online std: [0.98260742 0.97492802 0.98959768 1.01408439]\n","Offline mean: [-0.00243011 -0.00168271  0.00190514 -0.01624116], offline std: [0.98250916 0.97483053 0.98949872 1.01398299]\n"],"name":"stdout"}]},{"metadata":{"id":"tmCCp8carM01","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"773f12e1-27dd-4b32-9539-582a1bdeacb0","executionInfo":{"status":"ok","timestamp":1550224333887,"user_tz":-60,"elapsed":478,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}}},"cell_type":"code","source":["seq_len = 10\n","feature_size = 3\n","batch_size = 4\n","num_epochs = 2\n","eval_frequency = 2  # in number of training steps.\n","\n","# samples = np.random.randint(0, 10, (batch_size*5, seq_len, feature_size))\n","# labels = np.random.randint(0, 10, (batch_size*5, seq_len, feature_size))\n","# eval_samples = np.random.randint(10, 15, (batch_size*2, seq_len, feature_size))\n","# eval_labels = np.random.randint(10, 15, (batch_size*2, seq_len, feature_size))\n","\n","# Non-sequential data.\n","samples = np.random.randint(0, 10, (batch_size*5, feature_size))\n","labels = np.random.randint(0, 10, (batch_size*5, feature_size))\n","eval_samples = np.random.randint(10, 15, (batch_size*2+1, feature_size))\n","eval_labels = np.random.randint(10, 15, (batch_size*2+1, feature_size))\n","\n","# Listed numbers\n","samples = np.array(range(batch_size*5+3))\n","labels = np.array(range(batch_size*5+3))\n","eval_samples = np.array(range(batch_size*5)) + 100\n","eval_labels = np.array(range(batch_size*5)) + 100\n","\n","def normalize(sample):\n","  sample[\"inputs\"] = (sample[\"inputs\"]-10)\n","  return sample\n","\n","print(samples)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n"],"name":"stdout"}]},{"metadata":{"id":"u96H8QG2QGXU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"60de9e56-bd24-4d62-aeda-ea4e70d6a716","executionInfo":{"status":"ok","timestamp":1550224337757,"user_tz":-60,"elapsed":724,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}}},"cell_type":"code","source":["# Eager Mode v1: we don't need to create any iterators. \n","\n","training_dataset = tf.data.Dataset.from_tensor_slices({\"inputs\":samples, \"targets\":labels})\n","# training_dataset = training_dataset.batch(batch_size).repeat(num_epochs).shuffle(buffer_size=10)\n","training_dataset = training_dataset.map(normalize)\n","training_dataset = training_dataset.batch(batch_size)\n","\n","eval_dataset = tf.data.Dataset.from_tensor_slices({\"inputs\":eval_samples, \"targets\":eval_labels})\n","eval_dataset = eval_dataset.batch(batch_size)\n","\n","iterator = training_dataset.make_one_shot_iterator()\n","features = iterator.get_next()\n","print(features)\n","for batch in iterator:\n","    pass\n","\n","print(\"End of the first epoch.\")\n","iterator = training_dataset.make_one_shot_iterator()\n","features = iterator.get_next()\n","print(features)\n","\n","\"\"\"\n","for epoch in range(num_epochs):\n","  print(\"Epoch \" + str(epoch+1))\n","  for train_batch in training_dataset:\n","    print(train_batch[\"inputs\"])\n","\n","print(\"End of Training.\")\n","\"\"\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-3-ee5bfa8cda98>:10: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","{'inputs': <tf.Tensor: id=24, shape=(4,), dtype=int64, numpy=array([-10,  -9,  -8,  -7])>, 'targets': <tf.Tensor: id=25, shape=(4,), dtype=int64, numpy=array([0, 1, 2, 3])>}\n","End of the first epoch.\n","{'inputs': <tf.Tensor: id=45, shape=(4,), dtype=int64, numpy=array([-10,  -9,  -8,  -7])>, 'targets': <tf.Tensor: id=46, shape=(4,), dtype=int64, numpy=array([0, 1, 2, 3])>}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'\\nfor epoch in range(num_epochs):\\n  print(\"Epoch \" + str(epoch+1))\\n  for train_batch in training_dataset:\\n    print(train_batch[\"inputs\"])\\n\\nprint(\"End of Training.\")\\n'"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"z9mPnRZ3J1Xt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":827},"outputId":"def7653d-2210-42b3-df24-8bc53d83c263","executionInfo":{"status":"ok","timestamp":1549630520171,"user_tz":-60,"elapsed":546,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}}},"cell_type":"code","source":["# Eager Mode v2: only make_one_shot_iterator is supported. Make one pass and \n","# recreate the iterator. Not sure about the cost of creating an iterator.\n","\n","training_dataset = tf.data.Dataset.from_tensor_slices({\"inputs\":samples, \"targets\":labels})\n","training_dataset = training_dataset.batch(batch_size)\n","training_dataset = training_dataset.shuffle(buffer_size=10)\n","training_iterator = training_dataset.make_one_shot_iterator()\n","\n","eval_dataset = tf.data.Dataset.from_tensor_slices({\"inputs\":eval_samples, \"targets\":eval_labels})\n","eval_dataset = eval_dataset.batch(batch_size)\n","eval_iterator = eval_dataset.make_one_shot_iterator()\n","\n","for epoch in range(num_epochs):\n","  # Training.\n","  try:\n","    for step in range(eval_frequency):\n","      tf_training_pl = training_iterator.get_next()\n","      train_batch = tf_training_pl[\"inputs\"]\n","      print(train_batch)\n","\n","    # Evaluation: make a full pass on the evaluation data.\n","    while True:\n","      try:\n","        tf_eval_pl = eval_iterator.get_next()\n","        eval_batch = tf_eval_pl[\"inputs\"]\n","        print(eval_batch)\n","      except tf.errors.OutOfRangeError:\n","        eval_iterator = eval_dataset.make_one_shot_iterator()\n","        print(\"End of Evaluation.\")\n","        break\n","  \n","  except tf.errors.OutOfRangeError:\n","    training_iterator = training_dataset.make_one_shot_iterator()\n","    print(\"Epoch \" + str(epoch+1))\n","    \n","print(\"End of Training.\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[0 6 5]\n"," [2 1 9]\n"," [1 3 7]\n"," [3 1 2]], shape=(4, 3), dtype=int64)\n","tf.Tensor(\n","[[6 9 0]\n"," [0 4 1]\n"," [3 8 4]\n"," [8 7 9]], shape=(4, 3), dtype=int64)\n","tf.Tensor(\n","[[10 11 13]\n"," [11 10 11]\n"," [14 12 12]\n"," [12 11 13]], shape=(4, 3), dtype=int64)\n","tf.Tensor(\n","[[10 10 10]\n"," [10 11 10]\n"," [10 13 13]\n"," [10 14 11]], shape=(4, 3), dtype=int64)\n","tf.Tensor([[11 14 10]], shape=(1, 3), dtype=int64)\n","End of Evaluation.\n","tf.Tensor(\n","[[5 6 2]\n"," [2 0 1]\n"," [5 7 9]\n"," [0 7 0]], shape=(4, 3), dtype=int64)\n","tf.Tensor(\n","[[7 1 1]\n"," [0 8 6]\n"," [6 5 2]\n"," [3 6 0]], shape=(4, 3), dtype=int64)\n","tf.Tensor(\n","[[10 11 13]\n"," [11 10 11]\n"," [14 12 12]\n"," [12 11 13]], shape=(4, 3), dtype=int64)\n","tf.Tensor(\n","[[10 10 10]\n"," [10 11 10]\n"," [10 13 13]\n"," [10 14 11]], shape=(4, 3), dtype=int64)\n","tf.Tensor([[11 14 10]], shape=(1, 3), dtype=int64)\n","End of Evaluation.\n","End of Training.\n"],"name":"stdout"}]},{"metadata":{"id":"psRSf2SRmZTF","colab_type":"code","outputId":"c5067833-84ed-4f67-f1f2-f20855bc848e","executionInfo":{"status":"ok","timestamp":1549623685610,"user_tz":-60,"elapsed":663,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}},"colab":{"height":35}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["End of Training.\n"],"name":"stdout"}]},{"metadata":{"id":"pnp8CkxDrBXF","colab_type":"code","outputId":"0ad43a89-62b1-40f8-b767-05bcb4f58ddc","executionInfo":{"status":"error","timestamp":1549628495806,"user_tz":-60,"elapsed":595,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}},"colab":{"height":496}},"cell_type":"code","source":["# Static Mode: the evaluation iterator is reinitialized after a full pass.\n","# The training data is repeated for number of epochs and processed via a\n","# one shot iterator. We can also use an initializable iterator similar to \n","# evaluation case.\n","\n","training_dataset = tf.data.Dataset.from_tensor_slices({\"inputs\":samples, \"targets\":labels})\n","training_dataset = training_dataset.batch(batch_size)\n","training_dataset = training_dataset.repeat(num_epochs)\n","training_dataset = training_dataset.shuffle(buffer_size=10)\n","training_iterator = training_iterator.make_one_shot_iterator()\n","tf_training_pl = training_iterator.get_next()\n","\n","eval_dataset = tf.data.Dataset.from_tensor_slices({\"inputs\":eval_samples, \"targets\":eval_labels})\n","eval_dataset = eval_dataset.batch(batch_size)\n","eval_iterator = eval_dataset.make_initializable_iterator()\n","tf_eval_pl = eval_iterator.get_next()\n","\n","\n","while True:\n","  # Training.\n","  try:\n","    for step in range(eval_frequency):\n","      train_batch = sess.run(tf_training_pl[\"inputs\"])\n","      print(train_batch)\n","\n","    # Evaluation: make a full pass on the evaluation data.\n","    sess.run(eval_iterator.initializer)\n","    while True:\n","      try:\n","        eval_batch = sess.run(tf_eval_pl[\"inputs\"])\n","        print(eval_batch)\n","      except tf.errors.OutOfRangeError:\n","        print(\"End of Evaluation.\")\n","        break\n","  \n","  except tf.errors.OutOfRangeError:\n","    print(\"End of Training.\")\n","    break"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m<ipython-input-4-9189653fe639>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0meval_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"inputs\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0meval_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"targets\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0meval_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0meval_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0meval_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_initializable_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mtf_eval_pl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_pool_mlwtfself_25.kernel.colaboratory-playground.212957554286.14b334fb3717c109/mount/server/colab_notebook.par/google3/third_party/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_initializable_iterator\u001b[1;34m(self, shared_name)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1577\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmake_initializable_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshared_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1578\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_initializable_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshared_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_pool_mlwtfself_25.kernel.colaboratory-playground.212957554286.14b334fb3717c109/mount/server/colab_notebook.par/google3/third_party/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_initializable_iterator\u001b[1;34m(self, shared_name)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m       raise RuntimeError(\n\u001b[1;32m--> 163\u001b[1;33m           \u001b[1;34m\"dataset.make_initializable_iterator is not supported when eager \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m           \"execution is enabled.\")\n\u001b[0;32m    165\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: dataset.make_initializable_iterator is not supported when eager execution is enabled."]}]},{"metadata":{"id":"Dq6rbfTUB5UI","colab_type":"code","outputId":"25304b1d-7619-4569-bcb5-a61326fdb420","executionInfo":{"status":"error","timestamp":1549630551124,"user_tz":-60,"elapsed":530,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}},"colab":{"base_uri":"https://localhost:8080/","height":478}},"cell_type":"code","source":["eval_iterator = eval_dataset.make_initializable_iterator()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-5-86dea3e42665>:1: make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-5-86dea3e42665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_initializable_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/dataset_ops.pyc\u001b[0m in \u001b[0;36mmake_initializable_iterator\u001b[0;34m(self, shared_name)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m       raise RuntimeError(\n\u001b[0;32m-> 1405\u001b[0;31m           \u001b[0;34m\"dataset.make_initializable_iterator is not supported when eager \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m           \"execution is enabled.\")\n\u001b[1;32m   1407\u001b[0m     \u001b[0m_ensure_same_dataset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: dataset.make_initializable_iterator is not supported when eager execution is enabled."]}]},{"metadata":{"id":"CMOPN03KCzXJ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}