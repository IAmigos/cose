{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_basic_lstm_diagram_model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["q5u31Dft_ZA2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"rSndAetdIxBa","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qsf7eDuk8XrL","colab_type":"code","colab":{}},"cell_type":"code","source":["class Constants(object):\n","    \"\"\" Constant strings to be used in the code. \"\"\"\n","    SEED = 1234\n","\n","    # Models.\n","    MODEL_RNN = \"rnn\"\n","    MODEL_VRNN = \"vrnn\"\n","    MODEL_TCN = \"tcn\"\n","\n","    # Negative log-likelihood losses.\n","    NLL_BERNOULLI = 'nll_bernoulli'\n","    NLL_NORMAL = 'nll_normal'\n","    NLL_BINORMAL = 'nll_binormal'\n","    NLL_GMM = 'nll_gmm'\n","    NLL_BIGMM = 'nll_bigmm'\n","    NLL_CENT = 'nll_cent'  # Cross-entropy.\n","    NLL_CENT_BINARY = 'nll_cent_binary'  # Cross-entropy for binary outputs.\n","    KLD = 'kld'\n","    L1 = 'l1'\n","    MSE = 'mse'\n","\n","    # RNN cells and layer types.\n","    LSTM = 'lstm'\n","    GRU = 'gru'\n","    DENSE = \"dense\"  # Fully connected layer.\n","    TCN = \"tcn\"  # Temporal convolutional layer, i.e., causal 1D convolution.\n","\n","    # Activation functions.\n","    RELU = 'relu'\n","    ELU = 'elu'\n","    SIGMOID = 'sigmoid'\n","    SOFTPLUS = 'softplus'\n","    TANH = 'tanh'\n","    SOFTMAX = 'softmax'\n","    LRELU = 'lrelu'\n","    CLRELU = 'clrelu'  # Clamped leaky relu.\n","\n","    # Learning rate scheduler types.\n","    LR_EXP = \"exponential\"\n","    LR_CONSTANT = \"constant\"\n","\n","    # Loss reduce function types.\n","    R_MEAN_STEP = 'mean_step_loss'  # Take average of average step loss per sample over batch. Uses sequence length.\n","    R_MEAN_SEQUENCE = 'mean_sequence_loss'  # Take average of sequence loss (summation of all steps) over batch. Uses sequence length.\n","    R_MEAN = 'mean'  # Calculate average of the whole loss tensor.\n","    R_SUM = 'sum'  # Sum all entries in the loss tensor.\n","    B_MEAN_STEP = 'batch_mean_step_loss'  # Keep the loss per sample. Uses sequence length.\n","    R_IDENTITY = 'identity'  # No effect.\n","\n","    # Optimizers\n","    OPTIMIZER_ADAM = \"adam\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ldwCYQCHpobX","colab_type":"text"},"cell_type":"markdown","source":["# Tensorflow Model Utils"]},{"metadata":{"id":"EnbN_EqfpuBg","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_activation_fn(activation=C.RELU):\n","    \"\"\"\n","    Return tensorflow activation function given string name.\n","    Args:\n","        activation (str): name of the activation function.\n","    Returns:\n","        TF activation function or None.\n","    \"\"\"\n","    # Check if the activation is already callable.\n","    if callable(activation):\n","        return activation\n","    # Check if the activation is a built-in or custom function.\n","    if activation == C.RELU:\n","        return tf.nn.relu\n","    elif activation == C.ELU:\n","        return tf.nn.elu\n","    elif activation == C.TANH:\n","        return tf.nn.tanh\n","    elif activation == C.SIGMOID:\n","        return tf.nn.sigmoid\n","    elif activation == C.SOFTPLUS:\n","        return tf.nn.softplus\n","    elif activation == C.SOFTMAX:\n","        return tf.nn.softmax\n","    elif activation == C.LRELU:\n","        return lambda x: tf.nn.leaky_relu(x, alpha=1. / 3.)\n","    elif activation == C.CLRELU:\n","        with tf.name_scope('ClampedLeakyRelu'):\n","            return lambda x: tf.clip_by_value(tf.nn.leaky_relu(x, alpha=1. / 3.), -3.0, 3.0)\n","    elif activation is None:\n","        return None\n","    else:\n","        raise Exception(\"Unknown activation function\")\n","\n","class CausalConv1D(tf.layers.Conv1D):\n","    def __init__(self, filters, kernel_size, dilation_rate=1,\n","                 activation=None, trainable=True, name=None, **kwargs):\n","        super(CausalConv1D, self).__init__(filters=filters,\n","                                           kernel_size=kernel_size,\n","                                           padding='valid',\n","                                           dilation_rate=dilation_rate,\n","                                           activation=activation,\n","                                           trainable=trainable,\n","                                           name=name, **kwargs)\n","\n","    def call(self, inputs):\n","        padding = (self.kernel_size[0] - 1) * self.dilation_rate[0]\n","        inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)\n","        return super(CausalConv1D, self).call(inputs)\n","\n","\n","class DenseLayer(tf.keras.models.Sequential):\n","    \"\"\"\n","    Stacks a number of dense layers by allowing applying dropout on the inputs and activation function on the outputs\n","    of every dense layer.\n","    \"\"\"\n","    def __init__(self, units, num_layers, activation_fn, dropout_rate=0, **kwargs):\n","        super(DenseLayer, self).__init__(**kwargs)\n","\n","        self.units = units if isinstance(units, list) else [units] * self.num_layers\n","        self.num_layers = num_layers\n","        self.dropout_rate = dropout_rate if isinstance(dropout_rate, list) else [dropout_rate] * self.num_layers\n","        self.activation_fn = get_activation_fn(activation_fn)\n","\n","        for idx in range(self.num_layers):\n","            if self.dropout_rate[idx] > 0:\n","                self.add(tf.keras.layers.Dropout(self.dropout_rate[idx], name=self.name + \"_dropout\" + str(idx)))\n","            self.add(tf.keras.layers.Dense(self.units[idx], self.activation_fn, name=self.name + \"_\" + str(idx)))\n","\n","    def call(self, inputs, training=None, mask=None):\n","        out = super(DenseLayer, self).call(inputs, training=training, mask=mask)\n","        return out\n","\n","    def get_config(self):\n","        base_config = super(DenseLayer, self).get_config()\n","        return base_config"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FpGsikuabdUW","colab_type":"text"},"cell_type":"markdown","source":["# Configuration Class"]},{"metadata":{"id":"KaHVUnvJWjRX","colab_type":"code","colab":{}},"cell_type":"code","source":["import json\n","import os\n","\n","class AttrDict(dict):\n","    def __init__(self, **kwargs):\n","        super(AttrDict, self).__init__(**kwargs)\n","\n","    __getattr__ = dict.__getitem__\n","    __setattr__ = dict.__setitem__\n","\n","\n","class DenseLayerConfig(AttrDict):\n","    \"\"\" A template configuration for dense network. \"\"\"\n","    def __init__(self, layers=None, units=None, activation=None, dropout_rate=0.0, **kwargs):\n","        super(DenseLayerConfig, self).__init__(**kwargs)\n","        self.type = C.DENSE\n","        self.layers = layers\n","        self.units = units\n","        self.activation = activation\n","        self.dropout_rate = dropout_rate\n","\n","\n","class TCNLayerConfig(AttrDict):\n","    \"\"\" A template configuration for temporal convolutional network. \"\"\"\n","    def __init__(self, layers=None, units=None, activation=None, filters=None, kernel_width=2, strides=1, dilation=1, **kwargs):\n","        super(TCNLayerConfig, self).__init__(**kwargs)\n","        self.type = C.TCN\n","        self.layers = layers\n","        self.units = units\n","        self.activation = activation\n","        self.filters = filters\n","        self.kernel_width = kernel_width\n","        self.strides = strides\n","        self.dilation = dilation\n","\n","\n","class RNNLayerConfig(AttrDict):\n","    \"\"\" A template configuration for RNN network. \"\"\"\n","    def __init__(self, type, layers, units, activation, **kwargs):\n","        super(RNNLayerConfig, self).__init__(**kwargs)\n","        self.type = type\n","        self.layers = layers\n","        self.units = units\n","        self.activation = activation\n","\n","\n","class LossConfig(AttrDict):\n","    \"\"\" A template configuration for defining loss terms. \"\"\"\n","    def __init__(self, type=None, out_key=None, target_key=None, weight=1, **kwargs):\n","        super(LossConfig, self).__init__(**kwargs)\n","        self.type = None  # see constants for the options.\n","        self.out_key = None  # key/name of the tensorflow op. looks for <out_key> in model outputs.\n","        self.target_key = None  # key/name of the target data placeholder.\n","        self.weight = weight\n","\n","\n","class Configuration(AttrDict):\n","    \"\"\" Main configuration class for defining models and experiments. \"\"\"\n","    def __init__(self, **kwargs):\n","        super(Configuration, self).__init__(**kwargs)\n","        self.loss = AttrDict()\n","\n","    def dump(self, path):\n","        json.dump(self, open(os.path.join(path, 'config.json'), 'w'), indent=4, sort_keys=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q5u31Dft_ZA2","colab_type":"text"},"cell_type":"markdown","source":["#Model Class"]},{"metadata":{"id":"rMWnnzlV_fRE","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_tf_estimator(inputs, targets, mode, config):\n","    model = None\n","    if config.model == C.MODEL_RNN:\n","      model = RNN(inputs, targets, mode, config)\n","    else:\n","      raise Exception(\"Unknown model type.\")\n","    \n","    model.build_graph()\n","    \n","    return tf.estimator.EstimatorSpec(\n","      mode=mode,\n","      predictions=model.dict_predictions,\n","      loss=model.training_objective,\n","      train_op=model.training_op,\n","      eval_metric_ops=None)\n","  \n","\n","class BaseTemporalModel(object):\n","  def __init__(self, inputs, targets, mode, config, **kwargs):\n","    self.config = None\n","    self.mode = None\n","    self.inputs = None\n","    self.targets = None\n","    \n","    # Total loss constructed by build_objective method.\n","    self.training_objective = None\n","    # Tensorflow training op constructed by build_optimizer method.\n","    self.training_op = None\n","    \n","    # A container for model outputs.\n","    self.dict_predictions = dict()\n","    \n","    # A container for loss terms.\n","    self.dict_loss_terms = dict()\n","    \n","  def build_graph(self):\n","    \"\"\"\n","    Composing parts of model and builds the final tensorflow computational \n","    graph by building the model and loss.\n","    \"\"\"\n","    self.build_network()\n","    self.build_loss_terms()\n","    self.build_objective()\n","    self.build_optimizer()\n","\n","  def build_network(self):\n","    \"\"\"\n","    Builds internal dynamics of the model.\n","    \"\"\"\n","    raise NotImplementedError('Subclasses must override.')\n","  \n","  def build_input_layer(self):\n","    \"\"\"Maps the data inputs to an intermediate representation.\"\"\"\n","    pass\n","  \n","  def build_output_layer(self):\n","    \"\"\"Builds the model predictions based on the loss configuration\"\"\"\n","    pass\n","      \n","  def build_loss_terms(self):\n","    \"\"\"\n","    Builds loss terms for training objective or monitoring.\n","    \"\"\"\n","    raise NotImplementedError('Subclasses must override.')\n","    \n","  def build_objective(self):\n","    \"\"\"\n","    Builds training objective.\n","    \"\"\"\n","    raise NotImplementedError('Subclasses must override.')\n","    \n","  def build_optimizer(self):\n","    \"\"\"\n","    Builds optimizer and training op.\n","    \"\"\"\n","    train_op = tf.contrib.layers.optimize_loss(\n","      loss=self.training_objective,\n","      global_step=tf.train.get_global_step(),\n","      learning_rate=self.config.experiment.learning_rate,\n","      optimizer=self.config.experiment.optimizer,\n","      clip_gradients=self.config.experiment.grad_clip_by_norm,\n","      summaries=[\"learning_rate\", \"loss\", \"global_gradient_norm\"])\n","  \n","    return train_op\n","  \n","\n","class RNN(BaseTemporalModel):\n","  \"\"\"A standard Recurrent Neural Network model. \"\"\"\n","  def __init__(self, inputs, targets, mode, config, **kwargs):\n","    super(VHRED, self).__init__(inputs, targets, mode, config, **kwargs)\n","\n","class VHRED(BaseTemporalModel):\n","  \"\"\"Latent Variable Hierarchical Recurrent Encoder-Decoder model.\n","  https://arxiv.org/abs/1605.06069\n","  \"\"\"\n","  def __init__(self, inputs, targets, mode, config, **kwargs):\n","    super(VHRED, self).__init__(inputs, targets, mode, config, **kwargs)\n","  \n","  def build_encoder(self, inputs, **kwargs):\n","    pass\n","  \n","  def build_decoder(self, inputs, **kwargs):\n","    pass\n","  \n","  def build_latent_space(self, inputs, **kwargs):\n","    \n","  \n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"sAMmGRonbiIP","colab_type":"text"},"cell_type":"markdown","source":["# Model and Experiment"]},{"metadata":{"id":"42yqgsIaJZSy","colab_type":"code","colab":{}},"cell_type":"code","source":["def define_config(dump_path=None):\n","    config = Configuration()\n","    \n","    config.input_layer = FCLayerConfig()\n","    config.input_layer.dropout_rate = 0.5\n","    config.input_layer.num_layers = 2\n","    config.input_layer.units = 256\n","    config.input_layer.activation = C.RELU\n","\n","    config.rnn_layer = FCLayerConfig()\n","    config.rnn_layer.type = C.LSTM\n","    config.rnn_layer.num_layers = 2\n","    config.rnn_layer.units = 256\n","    config.rnn_layer.activation = C.RELU\n","    \n","    config.output_layer = FCLayerConfig()\n","    config.output_layer.num_layers = 1\n","    config.output_layer.units = 256\n","    config.output_layer.activation_fn = C.RELU\n","    \n","    config.experiment = AttrDict()\n","    config.experiment.optimizer = C.OPTIMIZER_ADAM\n","    config.experiment.learning_rate = 1e-3\n","    config.experiment.learning_rate_type = C.LR_CONSTANT\n","    config.experiment.learning_rate_decay_steps = 1000\n","    config.experiment.learning_rate_decay_rate = 0.95\n","    config.experiment.batch_size = 20\n","    config.experiment.num_epochs = 100\n","    config.experiment.loss_reduce_type = C.R_MEAN_SEQUENCE\n","    config.experiment.grad_clip_by_norm = 1\n","    \n","    config.loss = AttrDict()\n","    config.loss.stroke = LossConfig(type=C.NLL_GMM, out_key=\"out\", weight=1, target_key=\"stroke\", num_components=20)\n","    config.loss.pen = LossConfig(type=C.NLL_BERNOULLI, out_key=\"out\", weight=1, target_key=\"pen\") \n","    \n","    if dump_path is not None:\n","      config.dump(dump_path)\n","    \n","    return config"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DMuflZWojfbw","colab_type":"code","outputId":"583300c1-8c36-463f-ffa2-3fdaa08d8838","executionInfo":{"status":"ok","timestamp":1543601678228,"user_tz":-60,"elapsed":996,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["test_config = define_config()\n","print(test_config.input_layer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'type': 'fc', 'num_layers': 2, 'size': None, 'activation': 'relu', 'dropout_rate': 0.5, 'units': 256}\n"],"name":"stdout"}]},{"metadata":{"id":"KLrS8duqX6Ml","colab_type":"code","outputId":"0a250d66-f398-4bb1-908f-6179a330d4ed","executionInfo":{"status":"error","timestamp":1543601679527,"user_tz":-60,"elapsed":788,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}},"colab":{"base_uri":"https://localhost:8080/","height":874}},"cell_type":"code","source":["dense_network = FCLayers(test_config.input_layer, name=\"input_layer\")\n","\n","np_data = np.random.normal(0, 1, (64, 4))\n","tf_input = tf.Variable(np_data, dtype=tf.float32)\n","tf_output = dense_network(tf_input)\n","dense_network.summary()\n","# tf_output = dense_network(tf_input)\n","# dense_network.summary()\n","\"\"\"\n","dense_network = DenseLayersTF(test_config.input_layer, name=\"input_layer\")\n","np_data = np.random.normal(0, 1, (64, 4))\n","tf_input = tf.Variable(np_data, dtype=tf.float32)\n","tf_output = dense_network(tf_input)\n","dense_network.get_weights()\n","\"\"\""],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-9825fcb00a0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdense_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# tf_output = dense_network(tf_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-8cddef8393c2>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFCLayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     outputs, _ = self._call_and_compute_mask(\n\u001b[0;32m--> 232\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m_call_and_compute_mask\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_compute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'kernel'"]}]},{"metadata":{"id":"SNiRUD1lywKL","colab_type":"code","colab":{}},"cell_type":"code","source":["encoder_model = tf.keras.models.Sequential(name=\"encoder\")\n","enc_dense1 = tf.keras.layers.Dense(10, name=\"enc_dense1\")\n","encoder_model.add(enc_dense1)\n","encoder_model.add(tf.keras.layers.Dense(32, name=\"enc_dense2\"))\n","encoder_model.add(tf.keras.layers.Dropout(0.5, name=\"enc_drop\"))\n","\n","decoder_model = tf.keras.models.Sequential(name=\"decoder\")\n","decoder_model.add(tf.keras.layers.Dropout(0.5, name=\"dec_drop\"))\n","decoder_model.add(tf.keras.layers.Dense(32, name=\"dec_dense1\"))\n","decoder_model.add(tf.keras.layers.Dense(10, name=\"dec_dense2\"))\n","\n","model = tf.keras.models.Sequential()\n","model.add(encoder_model)\n","model.add(decoder_model)\n","\n","np_data = np.random.normal(0, 1, (64, 4))\n","tf_input = tf.Variable(np_data, dtype=tf.float32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MJahismJz9yb","colab_type":"code","colab":{}},"cell_type":"code","source":["tf_output = model(tf_input)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"agCj13Cb0D9s","colab_type":"code","outputId":"e6e012f3-f5c2-4740-99ef-af29693f5059","executionInfo":{"status":"ok","timestamp":1542988502305,"user_tz":-60,"elapsed":1379,"user":{"displayName":"Emre Aksan","photoUrl":"","userId":"07313602013607958558"}},"colab":{"base_uri":"https://localhost:8080/","height":701}},"cell_type":"code","source":["encoder_model.summary()\n","decoder_model.summary()\n","model.summary()\n","model.compute_output_shape(tf_input.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","enc_dense1 (Dense)           multiple                  50        \n","_________________________________________________________________\n","enc_dense2 (Dense)           multiple                  352       \n","_________________________________________________________________\n","enc_drop (Dropout)           multiple                  0         \n","=================================================================\n","Total params: 402\n","Trainable params: 402\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dec_drop (Dropout)           multiple                  0         \n","_________________________________________________________________\n","dec_dense1 (Dense)           multiple                  1056      \n","_________________________________________________________________\n","dec_dense2 (Dense)           multiple                  330       \n","=================================================================\n","Total params: 1,386\n","Trainable params: 1,386\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","encoder (Sequential)         multiple                  402       \n","_________________________________________________________________\n","decoder (Sequential)         multiple                  1386      \n","=================================================================\n","Total params: 1,788\n","Trainable params: 1,788\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(10)])"]},"metadata":{"tags":[]},"execution_count":58}]},{"metadata":{"id":"Wnphm2F95FzN","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"XVnGSn_h67b9","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}