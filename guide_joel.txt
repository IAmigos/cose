// create a virtual env "env"

python3 -m venv env

// activating the virutal env 

source env/bin/activate

// check the env

which python

// leaving env

deactivate

// install req from txt

pip install -r requirements.txt

// output dependencies

pip freeze

// run train

python ink_training_eager_predictive.py --experiment_id test1 --gt_targets --use_start_pos --num_pred_inputs 32 --stop_predictive_grad --pred_input_type hybrid --stroke_loss nll_gmm --n_t_samples 4 --batch_size 128 --affine_prob 0.3 --resampling_factor 2 --scale_factor 0 --grad_clip_norm 1 --encoder_model transformer --transformer_scale --transformer_pos_encoding --transformer_layers 6 --transformer_heads 4 --transformer_dmodel 64 --transformer_hidden_units 256 --transformer_dropout 0.0 --latent_units 8 --decoder_model t_emb --decoder_dropout 0.0 --decoder_layers 4 --decoder_hidden_units 512,512,512,512 --predictive_model transformer --learning_rate_type transformer --p_transformer_layers 6 --p_transformer_heads 4 --p_transformer_dmodel 64 --p_transformer_hidden_units 256 --p_transformer_dropout 0.0 --p_transformer_scale --embedding_loss nll_gmm --embedding_gmm_components 10 --loss_predicted_embedding --loss_reconstructed_ink --position_model transformer --data_name didi_wo_text --metadata_type position --disable_pen_loss --mask_encoder_pen

// didi dataset in drive

https://drive.google.com/file/d/1mpQs3p9E7fJrLb_pO01m6Z_mfHm2ZIv5/view?usp=sharing

FILEID=1mpQs3p9E7fJrLb_pO01m6Z_mfHm2ZIv5
FILENAME=diagrams_wo_text_20200131.ndjson

// to download didi dataset

wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1mpQs3p9E7fJrLb_pO01m6Z_mfHm2ZIv5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=1mpQs3p9E7fJrLb_pO01m6Z_mfHm2ZIv5" -O diagrams_wo_text_20200131.ndjson && rm -rf /tmp/cookies.txt

COSE_DATA_DIR=/data/jcabrera
DATA_DIR=/data/jcabrera/didi_wo_text/

